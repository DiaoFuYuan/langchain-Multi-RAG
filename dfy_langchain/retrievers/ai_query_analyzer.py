#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIæŸ¥è¯¢åˆ†æå™¨
ä½¿ç”¨æ•°æ®åº“ä¸­é…ç½®çš„AIå¤§æ¨¡å‹è¿›è¡Œæ™ºèƒ½æŸ¥è¯¢ç†è§£ã€å®ä½“æå–å’Œè¯­ä¹‰åˆ†æ
"""

import os
import sys
import json
import logging
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from app.services.model_config_service import ModelConfigService
    from app.database import get_db
    from langchain_openai import ChatOpenAI
    from langchain.schema import HumanMessage, SystemMessage
    DB_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ æ•°æ®åº“æˆ–LangChainæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    DB_AVAILABLE = False

logger = logging.getLogger(__name__)


class AIQueryAnalyzer:
    """AIæŸ¥è¯¢åˆ†æå™¨ - ä½¿ç”¨æ•°æ®åº“é…ç½®çš„AIæ¨¡å‹"""
    
    def __init__(self, model_config_id: Optional[int] = None):
        """
        åˆå§‹åŒ–AIæŸ¥è¯¢åˆ†æå™¨
        
        Args:
            model_config_id: æ•°æ®åº“ä¸­çš„æ¨¡å‹é…ç½®IDï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„LLMæ¨¡å‹
        """
        self.model_config_id = model_config_id
        self.llm = None
        self.model_config = None
        self._initialize_llm()
        
    def _initialize_llm(self):
        """åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹"""
        if not DB_AVAILABLE:
            print("âŒ æ•°æ®åº“ä¸å¯ç”¨ï¼Œæ— æ³•åˆå§‹åŒ–AIæ¨¡å‹")
            return
            
        try:
            # è·å–æ•°æ®åº“è¿æ¥
            db = next(get_db())
            
            # è·å–æ¨¡å‹é…ç½®
            if self.model_config_id:
                model_config = ModelConfigService.get_model_config_by_id(db, self.model_config_id)
                if not model_config:
                    raise ValueError(f"æœªæ‰¾åˆ°IDä¸º {self.model_config_id} çš„æ¨¡å‹é…ç½®")
            else:
                # è·å–ç¬¬ä¸€ä¸ªå¯ç”¨çš„LLMæ¨¡å‹
                all_configs = ModelConfigService.get_all_model_configs(db)
                llm_configs = [config for config in all_configs 
                             if config.model_type == "llm" and config.test_status == "success"]
                
                if not llm_configs:
                    raise ValueError("æœªæ‰¾åˆ°å¯ç”¨çš„LLMæ¨¡å‹é…ç½®")
                
                model_config = llm_configs[0]
                self.model_config_id = model_config.id
            
            self.model_config = model_config
            
            # åˆ›å»ºChatOpenAIå®ä¾‹
            self.llm = ChatOpenAI(
                model_name=model_config.model_name,
                openai_api_key=model_config.api_key,
                openai_api_base=model_config.endpoint,
                temperature=0.1,  # ä½æ¸©åº¦ç¡®ä¿ç»“æœç¨³å®š
                max_tokens=model_config.max_tokens or 2000,
                request_timeout=30
            )
            
            print(f"âœ… AIæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: {model_config.provider_name} - {model_config.model_name}")
            
        except Exception as e:
            print(f"âŒ AIæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            logger.error(f"AIæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.llm = None
            self.model_config = None
    
    def analyze_query_with_ai(self, query: str) -> Dict[str, Any]:
        """ä½¿ç”¨AIå¤§æ¨¡å‹åˆ†ææŸ¥è¯¢"""
        if not self.llm:
            print("âš ï¸ AIæ¨¡å‹æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ")
            return self._fallback_analysis(query)
        
        try:
            print(f"ğŸ¤– ä½¿ç”¨AIæ¨¡å‹åˆ†ææŸ¥è¯¢: '{query}'")
            
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_prompt = self._build_system_prompt()
            
            # æ„å»ºç”¨æˆ·æŸ¥è¯¢
            user_prompt = self._build_user_prompt(query)
            
            # è°ƒç”¨AIæ¨¡å‹
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            
            response = self.llm(messages)
            result_text = response.content
            
            # è§£æAIè¿”å›çš„JSONç»“æœ
            analysis_result = self._parse_ai_response(result_text, query)
            
            print(f"ğŸ¯ AIåˆ†æå®Œæˆ:")
            print(f"  å®ä½“: {analysis_result.get('entities', {})}")
            print(f"  æŸ¥è¯¢æ„å›¾: {analysis_result.get('query_intent', 'unknown')}")
            print(f"  å…³é”®è¯: {analysis_result.get('keywords', [])}")
            
            return analysis_result
            
        except Exception as e:
            print(f"âš ï¸ AIåˆ†æå¤±è´¥: {e}")
            logger.error(f"AIåˆ†æå¤±è´¥: {e}")
            return self._fallback_analysis(query)
    
    def _build_system_prompt(self) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŸ¥è¯¢åˆ†æä¸“å®¶ï¼Œä¸“é—¨åˆ†æç”¨æˆ·çš„æŸ¥è¯¢æ„å›¾å¹¶æå–å…³é”®ä¿¡æ¯ã€‚

ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œæå–ä»¥ä¸‹ä¿¡æ¯ï¼š
1. äººå‘˜å®ä½“ï¼ˆå§“å+ç§°è°“ï¼Œå¦‚"é’Ÿå¥³å£«"ã€"æå…ˆç”Ÿ"ç­‰ï¼‰
2. ç»„ç»‡æœºæ„ï¼ˆå…¬å¸ã€éƒ¨é—¨ã€åŒ»é™¢ç­‰ï¼‰
3. åœ°ç‚¹ä¿¡æ¯ï¼ˆåŸå¸‚ã€åŒºåŸŸã€å…·ä½“åœ°å€ç­‰ï¼‰
4. æ—¶é—´ä¿¡æ¯ï¼ˆæ—¥æœŸã€æ—¶é—´æ®µç­‰ï¼‰
5. ä¸»é¢˜å…³é”®è¯ï¼ˆæŠ•è¯‰ã€å¤„ç†ã€æ£€æŸ¥ç­‰ï¼‰
6. æŸ¥è¯¢æ„å›¾åˆ†ç±»

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–æ–‡å­—ï¼š

{
  "entities": {
    "persons": ["æå–åˆ°çš„äººå‘˜å§“å"],
    "organizations": ["æå–åˆ°çš„ç»„ç»‡æœºæ„"],
    "locations": ["æå–åˆ°çš„åœ°ç‚¹"],
    "times": ["æå–åˆ°çš„æ—¶é—´"],
    "topics": ["æå–åˆ°çš„ä¸»é¢˜è¯"]
  },
  "query_intent": "æŸ¥è¯¢æ„å›¾åˆ†ç±»",
  "keywords": ["å…³é”®è¯åˆ—è¡¨"],
  "semantic_expansions": ["è¯­ä¹‰æ‰©å±•è¯"],
  "complexity_score": 0.0,
  "confidence": 0.0
}

æŸ¥è¯¢æ„å›¾åˆ†ç±»åŒ…æ‹¬ï¼š
- complaint_content: è¯¢é—®æŠ•è¯‰å†…å®¹
- complaint_handling: è¯¢é—®æŠ•è¯‰å¤„ç†æƒ…å†µ
- person_related: äººå‘˜ç›¸å…³æŸ¥è¯¢
- event_related: äº‹ä»¶ç›¸å…³æŸ¥è¯¢
- general: ä¸€èˆ¬æŸ¥è¯¢

è¯·ç¡®ä¿è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚"""

    def _build_user_prompt(self, query: str) -> str:
        """æ„å»ºç”¨æˆ·æç¤ºè¯"""
        return f"""è¯·åˆ†æä»¥ä¸‹æŸ¥è¯¢ï¼š

æŸ¥è¯¢å†…å®¹ï¼š{query}

è¯·æå–å…¶ä¸­çš„å®ä½“ä¿¡æ¯ã€åˆ¤æ–­æŸ¥è¯¢æ„å›¾ï¼Œå¹¶æŒ‰ç…§æŒ‡å®šçš„JSONæ ¼å¼è¿”å›ç»“æœã€‚

ç‰¹åˆ«æ³¨æ„ï¼š
1. äººå‘˜å§“åè¦åŒ…å«ç§°è°“ï¼ˆå¦‚"é’Ÿå¥³å£«"ã€"æå…ˆç”Ÿ"ï¼‰
2. æŠ•è¯‰ç›¸å…³æŸ¥è¯¢è¦å‡†ç¡®åˆ†ç±»æ„å›¾
3. å…³é”®è¯è¦æå–æœ€é‡è¦çš„3-5ä¸ªè¯
4. å¤æ‚åº¦è¯„åˆ†èŒƒå›´0-1ï¼Œè¶Šå¤æ‚åˆ†æ•°è¶Šé«˜
5. ç½®ä¿¡åº¦è¯„åˆ†èŒƒå›´0-1ï¼Œè¶Šç¡®å®šåˆ†æ•°è¶Šé«˜"""

    def _parse_ai_response(self, response_text: str, original_query: str) -> Dict[str, Any]:
        """è§£æAIè¿”å›çš„å“åº”"""
        try:
            # å°è¯•ç›´æ¥è§£æJSON
            if response_text.strip().startswith('{'):
                result = json.loads(response_text.strip())
                
                # éªŒè¯å’Œè¡¥å……å¿…è¦å­—æ®µ
                if "entities" not in result:
                    result["entities"] = {}
                if "query_intent" not in result:
                    result["query_intent"] = "general"
                if "keywords" not in result:
                    result["keywords"] = []
                if "complexity_score" not in result:
                    result["complexity_score"] = 0.3
                if "confidence" not in result:
                    result["confidence"] = 0.8
                
                return result
            
            # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œå°è¯•æå–JSONéƒ¨åˆ†
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                result = json.loads(json_str)
                return result
            
            # å¦‚æœéƒ½å¤±è´¥ï¼Œè¿”å›åŸºç¡€åˆ†æ
            print(f"âš ï¸ AIè¿”å›æ ¼å¼ä¸æ­£ç¡®ï¼Œä½¿ç”¨åŸºç¡€åˆ†æ: {response_text[:100]}...")
            return self._fallback_analysis(original_query)
            
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
            return self._fallback_analysis(original_query)
        except Exception as e:
            print(f"âš ï¸ å“åº”è§£æå¤±è´¥: {e}")
            return self._fallback_analysis(original_query)
    
    def _fallback_analysis(self, query: str) -> Dict[str, Any]:
        """å›é€€åˆ†ææ–¹æ³•ï¼ˆåŸºäºè§„åˆ™ï¼‰"""
        print(f"ğŸ”„ ä½¿ç”¨åŸºç¡€è§„åˆ™åˆ†æ: '{query}'")
        
        entities = {
            "persons": [],
            "organizations": [],
            "locations": [],
            "times": [],
            "topics": []
        }
        
        # åŸºç¡€äººå‘˜å§“åæå–
        import re
        person_patterns = [
            r'([ç‹æå¼ åˆ˜é™ˆæ¨é»„èµµå‘¨å´å¾å­™æœ±é©¬èƒ¡éƒ­æ—ä½•é«˜æ¢éƒ‘ç½—å®‹è°¢å”éŸ©æ›¹è®¸é‚“è§å†¯æ›¾ç¨‹è”¡å½­æ½˜è¢äºè‘£ä½™è‹å¶å•é­è’‹ç”°æœä¸æ²ˆå§œèŒƒæ±Ÿå‚…é’Ÿå¢æ±ªæˆ´å´”ä»»é™†å»–å§šæ–¹é‡‘é‚±å¤è°­éŸ¦è´¾é‚¹çŸ³ç†Šå­Ÿç§¦é˜è–›ä¾¯é›·ç™½é¾™æ®µéƒå­”é‚µå²æ¯›å¸¸ä¸‡é¡¾èµ–æ­¦åº·è´ºä¸¥å°¹é’±æ–½ç‰›æ´ªé¾šæ±¤é™¶é»æ¸©è«æ˜“æ¨Šä¹”æ–‡å®‰æ®·é¢œåº„ç« é²å€ªåºé‚¢ä¿ç¿Ÿè“è‚ä¸›å²³é½æ²¿][ä¸€-é¾¥]{1,3})(å…ˆç”Ÿ|å¥³å£«|åŒå¿—|è€å¸ˆ|åŒ»ç”Ÿ|æŠ¤å£«|ä¸»ä»»|ç»ç†|æ€»ç›‘|ä¸“å®¶|å±€é•¿|å¤„é•¿|ç§‘é•¿|ä¸»ç®¡)',
            r'([ä¸€-é¾¥]{2,4})(å…ˆç”Ÿ|å¥³å£«|åŒå¿—|è€å¸ˆ|åŒ»ç”Ÿ|æŠ¤å£«|ä¸»ä»»|ç»ç†|æ€»ç›‘|ä¸“å®¶|å±€é•¿|å¤„é•¿|ç§‘é•¿|ä¸»ç®¡)',
        ]
        
        for pattern in person_patterns:
            matches = re.findall(pattern, query)
            for match in matches:
                if isinstance(match, tuple):
                    person_name = match[0] + match[1]
                    entities["persons"].append(person_name)
        
        # åŸºç¡€ä¸»é¢˜è¯æå–
        topic_keywords = ['æŠ•è¯‰', 'ä¸¾æŠ¥', 'åæ˜ ', 'ç”³è¯‰', 'æ„è§', 'å»ºè®®', 'é—®é¢˜', 'äº‹ä»¶', 'æƒ…å†µ', 'å¤„ç†', 'è°ƒæŸ¥', 'æ£€æŸ¥']
        for keyword in topic_keywords:
            if keyword in query:
                entities["topics"].append(keyword)
        
        # åŸºç¡€æ„å›¾åˆ†æ
        query_intent = "general"
        if "æŠ•è¯‰" in query:
            if "å†…å®¹" in query or "ä»€ä¹ˆ" in query:
                query_intent = "complaint_content"
            elif "å¤„ç†" in query:
                query_intent = "complaint_handling"
            else:
                query_intent = "complaint_general"
        elif entities["persons"]:
            query_intent = "person_related"
        elif "äº‹ä»¶" in query or "æƒ…å†µ" in query:
            query_intent = "event_related"
        
        # åŸºç¡€å…³é”®è¯æå–
        keywords = []
        for word in ['æŠ•è¯‰', 'å¤„ç†', 'å†…å®¹', 'æƒ…å†µ', 'é—®é¢˜', 'äº‹ä»¶']:
            if word in query:
                keywords.append(word)
        
        return {
            "entities": entities,
            "query_intent": query_intent,
            "keywords": keywords,
            "semantic_expansions": [],
            "complexity_score": 0.3,
            "confidence": 0.6
        }
    
    def extract_entities_with_ai(self, text: str) -> Dict[str, List[str]]:
        """ä½¿ç”¨AIæå–å®ä½“"""
        analysis_result = self.analyze_query_with_ai(text)
        return analysis_result.get("entities", {})
    
    def analyze_query_intent_with_ai(self, query: str) -> str:
        """ä½¿ç”¨AIåˆ†ææŸ¥è¯¢æ„å›¾"""
        analysis_result = self.analyze_query_with_ai(query)
        return analysis_result.get("query_intent", "general")
    
    def generate_semantic_expansions_with_ai(self, query: str) -> List[str]:
        """ä½¿ç”¨AIç”Ÿæˆè¯­ä¹‰æ‰©å±•"""
        if not self.llm:
            return []
        
        try:
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªè¯­ä¹‰æ‰©å±•ä¸“å®¶ã€‚ç»™å®šä¸€ä¸ªæŸ¥è¯¢ï¼Œè¯·ç”Ÿæˆ3-5ä¸ªè¯­ä¹‰ç›¸å…³çš„æ‰©å±•è¯æˆ–çŸ­è¯­ã€‚

è¯·åªè¿”å›æ‰©å±•è¯åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦æ·»åŠ å…¶ä»–æ–‡å­—ã€‚"""
            
            user_prompt = f"è¯·ä¸ºä»¥ä¸‹æŸ¥è¯¢ç”Ÿæˆè¯­ä¹‰æ‰©å±•è¯ï¼š{query}"
            
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]
            
            response = self.llm(messages)
            expansions = [line.strip() for line in response.content.split('\n') if line.strip()]
            
            return expansions[:5]  # é™åˆ¶æ•°é‡
            
        except Exception as e:
            print(f"âš ï¸ AIè¯­ä¹‰æ‰©å±•å¤±è´¥: {e}")
            return []
    
    def is_available(self) -> bool:
        """æ£€æŸ¥AIåˆ†æå™¨æ˜¯å¦å¯ç”¨"""
        return self.llm is not None and self.model_config is not None
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯"""
        if not self.model_config:
            return {}
        
        return {
            "config_id": self.model_config_id,
            "provider": self.model_config.provider,
            "provider_name": self.model_config.provider_name,
            "model_name": self.model_config.model_name,
            "endpoint": self.model_config.endpoint
        }


def get_ai_query_analyzer(model_config_id: Optional[int] = None) -> AIQueryAnalyzer:
    """è·å–AIæŸ¥è¯¢åˆ†æå™¨å®ä¾‹"""
    return AIQueryAnalyzer(model_config_id)


# æµ‹è¯•å‡½æ•°
def test_ai_query_analyzer():
    """æµ‹è¯•AIæŸ¥è¯¢åˆ†æå™¨"""
    print("ğŸ§ª æµ‹è¯•AIæŸ¥è¯¢åˆ†æå™¨")
    
    analyzer = get_ai_query_analyzer()
    
    if not analyzer.is_available():
        print("âŒ AIåˆ†æå™¨ä¸å¯ç”¨")
        return
    
    print(f"âœ… ä½¿ç”¨æ¨¡å‹: {analyzer.get_model_info()}")
    
    test_queries = [
        "é’Ÿå¥³å£«çš„æŠ•è¯‰å†…å®¹æ˜¯ä»€ä¹ˆ",
        "æå¥³å£«æŠ•è¯‰äº†ä»€ä¹ˆé—®é¢˜",
        "å¼ å…ˆç”Ÿçš„æŠ•è¯‰å¤„ç†æƒ…å†µå¦‚ä½•"
    ]
    
    for query in test_queries:
        print(f"\nğŸ” åˆ†ææŸ¥è¯¢: '{query}'")
        result = analyzer.analyze_query_with_ai(query)
        print(f"  ç»“æœ: {json.dumps(result, ensure_ascii=False, indent=2)}")


if __name__ == "__main__":
    test_ai_query_analyzer() 