#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Excelå›é€€æ£€ç´¢å™¨
å½“å‘é‡å­˜å‚¨æ£€ç´¢å¤±è´¥æ—¶ï¼Œè‡ªåŠ¨å›é€€åˆ°Excelæ•°æ®æ£€ç´¢
"""

import pandas as pd
import os
from pathlib import Path
from typing import List, Dict, Any, Tuple
from langchain_core.documents import Document

class ExcelFallbackRetriever:
    """Excelå›é€€æ£€ç´¢å™¨"""
    
    def __init__(self, excel_paths: Dict[str, str] = None):
        """
        åˆå§‹åŒ–Excelå›é€€æ£€ç´¢å™¨
        
        å‚æ•°:
            excel_paths: çŸ¥è¯†åº“IDåˆ°Excelæ–‡ä»¶è·¯å¾„çš„æ˜ å°„
        """
        self.excel_paths = excel_paths or {
            "PMS": "data/knowledge_base/PMS/content/ä¿¡æ¯ç§‘ï¼ˆæŠ•è¯‰ï¼‰.xlsx"
        }
        self.excel_data = {}
        self.load_excel_files()
    
    def load_excel_files(self):
        """åŠ è½½æ‰€æœ‰Excelæ–‡ä»¶"""
        for kb_id, excel_path in self.excel_paths.items():
            if os.path.exists(excel_path):
                try:
                    print(f"ğŸ“„ åŠ è½½Excelæ–‡ä»¶: {excel_path}")
                    df = pd.read_excel(excel_path)
                    self.excel_data[kb_id] = df
                    print(f"âœ… æˆåŠŸåŠ è½½ {len(df)} è¡Œæ•°æ®åˆ°çŸ¥è¯†åº“ {kb_id}")
                except Exception as e:
                    print(f"âŒ åŠ è½½Excelæ–‡ä»¶å¤±è´¥ {excel_path}: {e}")
            else:
                print(f"âš ï¸ Excelæ–‡ä»¶ä¸å­˜åœ¨: {excel_path}")
    
    def search_excel_data(self, query: str, knowledge_base_ids: List[str] = None, top_k: int = 10) -> List[Tuple[Document, float]]:
        """
        åœ¨Excelæ•°æ®ä¸­æœç´¢ç›¸å…³è®°å½•
        
        å‚æ•°:
            query: æœç´¢æŸ¥è¯¢
            knowledge_base_ids: è¦æœç´¢çš„çŸ¥è¯†åº“IDåˆ—è¡¨
            top_k: è¿”å›çš„æœ€å¤§ç»“æœæ•°
            
        è¿”å›:
            (Document, score)å…ƒç»„åˆ—è¡¨
        """
        if not knowledge_base_ids:
            knowledge_base_ids = list(self.excel_data.keys())
        
        print(f"ğŸ” Excelå›é€€æ£€ç´¢: '{query}' åœ¨çŸ¥è¯†åº“ {knowledge_base_ids}")
        
        # é¢„å¤„ç†æŸ¥è¯¢è¯
        query_terms = self._preprocess_query(query)
        print(f"ğŸ” æœç´¢å…³é”®è¯: {query_terms}")
        
        all_results = []
        
        for kb_id in knowledge_base_ids:
            if kb_id not in self.excel_data:
                continue
                
            df = self.excel_data[kb_id]
            kb_results = self._search_in_dataframe(df, query_terms, kb_id)
            all_results.extend(kb_results)
        
        # æŒ‰åˆ†æ•°æ’åºå¹¶è¿”å›top_kç»“æœ
        all_results.sort(key=lambda x: x[1], reverse=True)
        results = all_results[:top_k]
        
        print(f"ğŸ“Š Excelå›é€€æ£€ç´¢æ‰¾åˆ° {len(results)} ä¸ªåŒ¹é…è®°å½•")
        
        return results
    
    def _preprocess_query(self, query: str) -> List[str]:
        """é¢„å¤„ç†æŸ¥è¯¢è¯"""
        # ç§»é™¤åœç”¨è¯å’Œæ ‡ç‚¹ç¬¦å·
        query = query.replace('ï¼Œ', ' ').replace(',', ' ').replace('ï¼Ÿ', ' ').replace('?', ' ')
        query = query.replace('çš„', ' ').replace('æ˜¯ä»€ä¹ˆ', ' ').replace('å¤šå°‘æ¬¡', ' ').replace('äº†', ' ')
        
        query_terms = [term.strip() for term in query.split() if term.strip()]
        
        # æ·»åŠ å¤åˆè¯å¤„ç†
        additional_terms = []
        for term in query_terms:
            if 'æŠ•è¯‰' in term and len(term) > 2:
                additional_terms.extend(['æŠ•è¯‰', term.replace('æŠ•è¯‰', '').strip()])
            elif 'æä½³æ…§' in term and len(term) > 3:
                additional_terms.extend(['æä½³æ…§', term.replace('æä½³æ…§', '').strip()])
        
        query_terms.extend([term for term in additional_terms if term.strip()])
        
        return list(set(query_terms))  # å»é‡
    
    def _search_in_dataframe(self, df: pd.DataFrame, query_terms: List[str], kb_id: str) -> List[Tuple[Document, float]]:
        """åœ¨DataFrameä¸­æœç´¢"""
        results = []
        
        for idx, row in df.iterrows():
            score = 0
            matched_fields = []
            
            # æ£€æŸ¥æ¯ä¸ªå­—æ®µæ˜¯å¦åŒ…å«æŸ¥è¯¢è¯
            for col in df.columns:
                if pd.notna(row[col]):
                    cell_value = str(row[col]).lower()
                    for term in query_terms:
                        if term.lower() in cell_value:
                            # é‡è¦å­—æ®µåŠ æƒ
                            weight = 3 if col in ['æä¾›æ–¹å§“å'] else 2 if col in ['å…·ä½“é—®é¢˜', 'è¯‰æ±‚å†…å®¹'] else 1
                            score += weight
                            matched_fields.append(f"{col}:{row[col]}")
            
            # ç‰¹æ®Šå¤„ç†ï¼šäººååŒ¹é…
            if any(term in ['æä½³æ…§'] for term in query_terms):
                if 'æä½³æ…§' in str(row.get('æä¾›æ–¹å§“å', '')):
                    score += 20  # å¤§å¹…æå‡äººååŒ¹é…çš„åˆ†æ•°
            
            if score > 0:
                # åˆ›å»ºDocumentå¯¹è±¡
                doc_content = self._create_document_content(row, df.columns, idx + 1)
                
                doc = Document(
                    page_content=doc_content,
                    metadata={
                        'source': self.excel_paths.get(kb_id, f'{kb_id}_excel'),
                        'row': idx + 1,
                        'doc_id': f"{kb_id}_excel_row_{idx}",
                        'knowledge_base_id': kb_id,
                        'matched_fields': matched_fields,
                        'retriever_type': 'excel_fallback'
                    }
                )
                
                results.append((doc, float(score)))
        
        return results
    
    def _create_document_content(self, row: pd.Series, columns: List[str], row_num: int) -> str:
        """åˆ›å»ºæ–‡æ¡£å†…å®¹"""
        content_lines = [f"è®°å½• {row_num}:"]
        
        # æŒ‰é‡è¦æ€§æ’åºå­—æ®µ
        important_fields = ['ç™»è®°ç¼–å·', 'æä¾›æ–¹å§“å', 'æä¾›æ–¹è”ç³»æ–¹å¼', 'å…·ä½“é—®é¢˜', 'è¯‰æ±‚å†…å®¹', 'åŠç†æƒ…å†µçŠ¶æ€']
        other_fields = [col for col in columns if col not in important_fields]
        
        # å…ˆæ˜¾ç¤ºé‡è¦å­—æ®µ
        for col in important_fields:
            if col in columns and pd.notna(row[col]) and str(row[col]).strip():
                content_lines.append(f"{col}: {row[col]}")
        
        # å†æ˜¾ç¤ºå…¶ä»–å­—æ®µ
        for col in other_fields:
            if pd.notna(row[col]) and str(row[col]).strip():
                content_lines.append(f"{col}: {row[col]}")
        
        return "\n".join(content_lines)

# å…¨å±€å®ä¾‹
_excel_fallback_retriever = None

def get_excel_fallback_retriever():
    """è·å–Excelå›é€€æ£€ç´¢å™¨å®ä¾‹"""
    global _excel_fallback_retriever
    if _excel_fallback_retriever is None:
        _excel_fallback_retriever = ExcelFallbackRetriever()
    return _excel_fallback_retriever

def excel_fallback_search(query: str, knowledge_base_ids: List[str] = None, top_k: int = 10) -> List[Tuple[Document, float]]:
    """Excelå›é€€æœç´¢å‡½æ•°"""
    retriever = get_excel_fallback_retriever()
    return retriever.search_excel_data(query, knowledge_base_ids, top_k) 