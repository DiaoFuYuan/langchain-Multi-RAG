#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RAGæ£€ç´¢å™¨æ¨¡å—

æä¾›åŸºäºFAISSå‘é‡å­˜å‚¨çš„æ–‡æ¡£æ£€ç´¢åŠŸèƒ½ï¼Œæ”¯æŒå¤šçŸ¥è¯†åº“æ£€ç´¢å’Œä¸­æ–‡è·¯å¾„å¤„ç†ã€‚
"""

import os
import sys
import json
import tempfile
import shutil
from typing import List, Dict, Any, Optional, Union, Tuple
from dotenv import load_dotenv

# é…ç½®è·¯å¾„å’Œç¯å¢ƒ
current_dir = os.path.dirname(os.path.abspath(__file__))
env_path = os.path.join(current_dir, '.env')

# åŠ è½½ç¯å¢ƒå˜é‡
if os.path.exists(env_path):
    load_dotenv(env_path)
    print(f"å·²åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {env_path}")
else:
    print(f"ç¯å¢ƒå˜é‡æ–‡ä»¶ä¸å­˜åœ¨: {env_path}")

# ç¡®ä¿å¯ä»¥å¯¼å…¥å½“å‰ç›®å½•çš„æ¨¡å—
if current_dir not in sys.path:
    sys.path.append(current_dir)

load_dotenv()


class SimpleRetrieverService:
    """ç®€åŒ–çš„æ£€ç´¢å™¨æœåŠ¡ç±»ï¼ˆæ€»æ˜¯å¯ç”¨çš„åå¤‡æ–¹æ¡ˆï¼‰"""
    
    def __init__(self, vectorstore, top_k: int = 5):
        self.vectorstore = vectorstore
        self.top_k = top_k
        
    def get_relevant_documents(self, query: str) -> List:
        """è·å–ç›¸å…³æ–‡æ¡£"""
        if hasattr(self.vectorstore, 'similarity_search'):
            return self.vectorstore.similarity_search(query, k=self.top_k)
        return []
        
    def get_relevant_documents_with_scores(self, query: str) -> List[Tuple]:
        """è·å–å¸¦åˆ†æ•°çš„ç›¸å…³æ–‡æ¡£"""
        if hasattr(self.vectorstore, 'similarity_search_with_score'):
            return self.vectorstore.similarity_search_with_score(query, k=self.top_k)
        return []


class RetrieverServiceFactory:
    """æ£€ç´¢å™¨æœåŠ¡å·¥å‚ç±»"""
    
    def __init__(self, embedding_config=None):
        self._initialize_dependencies()
        self._initialize_embeddings(embedding_config)
    
    def _initialize_dependencies(self):
        """åˆå§‹åŒ–ä¾èµ–åº“"""
        try:
            import torch
            from langchain_community.vectorstores import FAISS
            from langchain_core.documents import Document
            
            # å°è¯•å¯¼å…¥æ–°çš„HuggingFaceEmbeddings
            try:
                from langchain_huggingface import HuggingFaceEmbeddings
                print("ä½¿ç”¨æ–°çš„langchain-huggingfaceåŒ…")
            except ImportError:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æ—§çš„åŒ…
                from langchain_community.embeddings import HuggingFaceEmbeddings
                print("ä½¿ç”¨æ—§çš„langchain-communityåŒ…")
            
            self.torch = torch
            self.FAISS = FAISS
            self.HuggingFaceEmbeddings = HuggingFaceEmbeddings
            self.Document = Document
            self.dependencies_available = True
            print("æˆåŠŸå¯¼å…¥æ‰€æœ‰å¿…è¦çš„åº“")
            
            # åˆå§‹åŒ– FAISS GPU æ”¯æŒ
            self._initialize_faiss_gpu()
            
            # å°è¯•å¯¼å…¥é«˜çº§æ£€ç´¢å™¨
            try:
                # å°è¯•ç»å¯¹å¯¼å…¥
                try:
                    from dfy_langchain.retrievers.ensemble_modules.basic_ensemble import EnsembleRetrieverService
                    from dfy_langchain.retrievers.vectorstore_modules.basic_vectorstore import VectorstoreRetrieverService
                    from dfy_langchain.retrievers.ensemble_modules.keyword_ensemble import KeywordEnsembleRetrieverService
                except ImportError:
                    # å›é€€åˆ°ç›¸å¯¹å¯¼å…¥
                    from .retrievers.ensemble import EnsembleRetrieverService
                    from .retrievers.vectorstore import VectorstoreRetrieverService
                    from .retrievers.keyword_ensemble import KeywordEnsembleRetrieverService
                
                self.EnsembleRetrieverService = EnsembleRetrieverService
                self.VectorstoreRetrieverService = VectorstoreRetrieverService
                self.KeywordEnsembleRetrieverService = KeywordEnsembleRetrieverService
                self.advanced_retrievers_available = True
                print("æˆåŠŸå¯¼å…¥é«˜çº§æ£€ç´¢å™¨")
            except ImportError as e:
                print(f"å¯¼å…¥é«˜çº§æ£€ç´¢å™¨å¤±è´¥: {e}")
                self.advanced_retrievers_available = False
                
        except ImportError as e:
            print(f"å¯¼å…¥åº“å¤±è´¥: {e}")
            self.dependencies_available = False
            self.advanced_retrievers_available = False
    
    def _initialize_faiss_gpu(self):
        """åˆå§‹åŒ– FAISS GPU æ”¯æŒ"""
        self.faiss_gpu_available = False
        self.gpu_resources = None
        
        try:
            import faiss
            self.faiss = faiss
            
            # æ£€æŸ¥ GPU å¯ç”¨æ€§
            if hasattr(faiss, 'get_num_gpus') and faiss.get_num_gpus() > 0:
                print(f"æ£€æµ‹åˆ° {faiss.get_num_gpus()} ä¸ª GPU")
                
                # åˆ›å»º GPU èµ„æº
                self.gpu_resources = faiss.StandardGpuResources()
                self.faiss_gpu_available = True
                print("FAISS GPU æ”¯æŒå·²å¯ç”¨")
            else:
                print("æœªæ£€æµ‹åˆ° GPU æˆ– FAISS GPU ä¸å¯ç”¨ï¼Œä½¿ç”¨ CPU æ¨¡å¼")
                
        except ImportError:
            print("FAISS åº“æœªå®‰è£…æˆ–ä¸æ”¯æŒ GPU")
        except Exception as e:
            print(f"åˆå§‹åŒ– FAISS GPU å¤±è´¥: {e}")
    
    def _initialize_embeddings(self, embedding_config=None):
        """åˆå§‹åŒ–åµŒå…¥æ¨¡å‹"""
        if not self.dependencies_available:
            self.embeddings = None
            return
        
        # å¦‚æœæä¾›äº†embeddingé…ç½®ï¼Œä¼˜å…ˆä½¿ç”¨è¿œç¨‹æ¨¡å‹
        if embedding_config:
            try:
                self.embeddings = self._create_remote_embeddings(embedding_config)
                if self.embeddings:
                    return
                print("è¿œç¨‹embeddingæ¨¡å‹åˆ›å»ºå¤±è´¥ï¼Œå›é€€åˆ°æœ¬åœ°æ¨¡å‹")
            except Exception as e:
                print(f"åˆ›å»ºè¿œç¨‹embeddingæ¨¡å‹å¤±è´¥: {e}ï¼Œå›é€€åˆ°æœ¬åœ°æ¨¡å‹")
        
        # åˆ›å»ºæœ¬åœ°embeddingæ¨¡å‹
        self._create_local_embeddings()
    
    def _create_remote_embeddings(self, embedding_config):
        """åˆ›å»ºè¿œç¨‹embeddingæ¨¡å‹"""
        try:
            # åŠ¨æ€å¯¼å…¥è¿œç¨‹embeddingæ¨¡å‹
            from embedding_model.local_embeddings import get_embedding_from_config
            
            print(f"RAGæ£€ç´¢ä½¿ç”¨è¿œç¨‹embeddingæ¨¡å‹: {embedding_config['model_name']} (provider: {embedding_config['provider']})")
            return get_embedding_from_config(config=embedding_config)
            
        except ImportError as e:
            print(f"æ— æ³•å¯¼å…¥è¿œç¨‹embeddingæ¨¡å—: {e}")
            return None
        except Exception as e:
            print(f"åˆ›å»ºè¿œç¨‹embeddingæ¨¡å‹å¤±è´¥: {e}")
            return None
    
    def _create_local_embeddings(self):
        """åˆ›å»ºæœ¬åœ°embeddingæ¨¡å‹"""
        # è·å–åµŒå…¥æ¨¡å‹è·¯å¾„
        embedding_model = os.getenv("EMBEDDING_MODEL_PATH", None)
        if embedding_model:
            # å¦‚æœç¯å¢ƒå˜é‡æä¾›äº†è·¯å¾„ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºç»å¯¹è·¯å¾„
            if os.path.isabs(embedding_model):
                embedding_model_path = embedding_model
            else:
                # ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
                embedding_model_path = os.path.join(current_dir, embedding_model)
        else:
            # é»˜è®¤è·¯å¾„ï¼šç›¸å¯¹äºå½“å‰ç›®å½•çš„embedding_model/bce-embedding-base_v1
            embedding_model_path = os.path.join(current_dir, "embedding_model", "bce-embedding-base_v1")
        
        print(f"å½“å‰ç›®å½•: {current_dir}")
        print(f"åµŒå…¥æ¨¡å‹è·¯å¾„: {embedding_model_path}")
        print(f"åµŒå…¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨: {os.path.exists(embedding_model_path)}")
        
        # æ£€æŸ¥åµŒå…¥æ¨¡å‹ç›®å½•
        embedding_dir = os.path.dirname(embedding_model_path)
        if os.path.exists(embedding_dir):
            print(f"åµŒå…¥æ¨¡å‹ç›®å½•å†…å®¹: {os.listdir(embedding_dir)}")
        
        # åˆ›å»ºåµŒå…¥æ¨¡å‹
        try:
            device = "cuda" if self.torch.cuda.is_available() else "cpu"
            self.embeddings = self.HuggingFaceEmbeddings(
                model_name=embedding_model_path,
                model_kwargs={"device": device},
                encode_kwargs={"normalize_embeddings": True}
            )
            print(f"æˆåŠŸåˆ›å»ºæœ¬åœ°åµŒå…¥æ¨¡å‹ï¼Œä½¿ç”¨è®¾å¤‡: {device}")
        except Exception as e:
            print(f"åˆ›å»ºæœ¬åœ°åµŒå…¥æ¨¡å‹å¤±è´¥: {e}")
            self.embeddings = None
    
    def _convert_index_to_gpu(self, vectorstore):
        """å°† FAISS ç´¢å¼•è½¬æ¢ä¸º GPU ç‰ˆæœ¬"""
        if not self.faiss_gpu_available or not hasattr(vectorstore, 'index'):
            return vectorstore
        
        try:
            # è·å–åŸå§‹ç´¢å¼•
            cpu_index = vectorstore.index
            
            # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å·²ç»åœ¨ GPU ä¸Š
            # GPU ç´¢å¼•çš„ç±»åé€šå¸¸åŒ…å« 'Gpu' å­—ç¬¦ä¸²
            index_type = type(cpu_index).__name__
            if 'Gpu' in index_type:
                print(f"ç´¢å¼•å·²ç»åœ¨ GPU ä¸Šï¼Œç±»å‹: {index_type}")
                return vectorstore
            
            print(f"åŸå§‹ç´¢å¼•ç±»å‹: {index_type}ï¼Œå‡†å¤‡è½¬æ¢ä¸º GPU")
            
            # å°†ç´¢å¼•è½¬ç§»åˆ° GPU
            gpu_index = self.faiss.index_cpu_to_gpu(
                self.gpu_resources, 
                0,  # GPU è®¾å¤‡ ID
                cpu_index
            )
            
            # æ›¿æ¢å‘é‡å­˜å‚¨ä¸­çš„ç´¢å¼•
            vectorstore.index = gpu_index
            gpu_index_type = type(gpu_index).__name__
            print(f"æˆåŠŸå°† FAISS ç´¢å¼•è½¬ç§»åˆ° GPUï¼Œç´¢å¼•å¤§å°: {gpu_index.ntotal}ï¼ŒGPU ç´¢å¼•ç±»å‹: {gpu_index_type}")
            
            return vectorstore
            
        except Exception as e:
            print(f"å°†ç´¢å¼•è½¬ç§»åˆ° GPU å¤±è´¥: {e}ï¼Œç»§ç»­ä½¿ç”¨ CPU ç´¢å¼•")
            return vectorstore
    
    def _optimize_gpu_index(self, vectorstore):
        """ä¼˜åŒ– GPU ç´¢å¼•æ€§èƒ½"""
        if not self.faiss_gpu_available or not hasattr(vectorstore, 'index'):
            return vectorstore
        
        try:
            index = vectorstore.index
            index_type = type(index).__name__
            
            # å¦‚æœç´¢å¼•åœ¨ GPU ä¸Šï¼Œè¿›è¡Œæ€§èƒ½ä¼˜åŒ–
            if 'Gpu' in index_type:
                print(f"æ­£åœ¨ä¼˜åŒ– GPU ç´¢å¼•ï¼Œç±»å‹: {index_type}")
                
                # è®¾ç½®æœç´¢å‚æ•°ä»¥ä¼˜åŒ–æ€§èƒ½
                if hasattr(index, 'nprobe'):
                    # å¯¹äº IVF ç´¢å¼•ï¼Œè®¾ç½®åˆé€‚çš„ nprobe å€¼
                    index.nprobe = min(32, max(1, index.nlist // 4))
                    print(f"è®¾ç½® GPU ç´¢å¼• nprobe ä¸º: {index.nprobe}")
                
                print("GPU ç´¢å¼•æ€§èƒ½ä¼˜åŒ–å®Œæˆ")
            else:
                print(f"ç´¢å¼•ä¸åœ¨ GPU ä¸Šï¼Œç±»å‹: {index_type}ï¼Œè·³è¿‡ GPU ä¼˜åŒ–")
            
            return vectorstore
            
        except Exception as e:
            print(f"GPU ç´¢å¼•ä¼˜åŒ–å¤±è´¥: {e}")
            return vectorstore
    
    def create_retriever_service(self, vectorstore, retriever_type="auto", **kwargs):
        """
        åˆ›å»ºæ£€ç´¢å™¨æœåŠ¡
        
        å‚æ•°:
            vectorstore: å‘é‡å­˜å‚¨
            retriever_type: æ£€ç´¢å™¨ç±»å‹ ("auto", "keyword_ensemble", "vectorstore", "hierarchical")
            **kwargs: å…¶ä»–å‚æ•°
        
        è¿”å›:
            æ£€ç´¢å™¨æœåŠ¡å®ä¾‹
        """
        
        # å¦‚æœæŒ‡å®šäº†åˆ†å±‚æ£€ç´¢
        if retriever_type == "hierarchical":
            hierarchical_retriever = self._create_hierarchical_retriever(vectorstore, **kwargs)
            if hierarchical_retriever:
                return hierarchical_retriever
            # å¦‚æœåˆ†å±‚æ£€ç´¢å¤±è´¥ï¼Œå›é€€åˆ°å…³é”®è¯ç»„åˆæ£€ç´¢
            print("åˆ†å±‚æ£€ç´¢åˆ›å»ºå¤±è´¥ï¼Œå›é€€åˆ°å…³é”®è¯ç»„åˆæ£€ç´¢")
            return self._create_keyword_ensemble_retriever(vectorstore, **kwargs)
        
        # å¦‚æœæŒ‡å®šäº†å…³é”®è¯ç»„åˆæ£€ç´¢
        if retriever_type == "keyword_ensemble":
            return self._create_keyword_ensemble_retriever(vectorstore, **kwargs)
        
        # å¦‚æœæŒ‡å®šäº†å‘é‡æ£€ç´¢
        if retriever_type == "vectorstore":
            return self._create_vectorstore_retriever(vectorstore, **kwargs)
        
        # è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ£€ç´¢å™¨
        if retriever_type == "auto":
            return self._create_auto_retriever(vectorstore, **kwargs)
        
        raise ValueError(f"ä¸æ”¯æŒçš„æ£€ç´¢å™¨ç±»å‹: {retriever_type}")    
    

    
    def _create_keyword_ensemble_retriever(self, vectorstore, **kwargs):
        """åˆ›å»ºå…³é”®è¯ç»„åˆæ£€ç´¢å™¨"""
        if not self.advanced_retrievers_available:
            return SimpleRetrieverService(vectorstore, kwargs.get('top_k', 10))
        
        try:
            return self.KeywordEnsembleRetrieverService.from_vectorstore(
                vectorstore=vectorstore,
                top_k=kwargs.get('top_k', 10),
                score_threshold=kwargs.get('score_threshold', 0.3),
                keyword_match_threshold=kwargs.get('keyword_match_threshold', 1),
                context_window=kwargs.get('context_window', 150),
                enable_ranking=kwargs.get('enable_ranking', True),
                weight_keyword_freq=kwargs.get('weight_keyword_freq', 0.4),
                weight_keyword_pos=kwargs.get('weight_keyword_pos', 0.3),
                weight_keyword_coverage=kwargs.get('weight_keyword_coverage', 0.3)
            )
        except Exception as e:
            print(f"åˆ›å»ºKeywordEnsembleRetrieverServiceå¤±è´¥: {e}")
            # å›é€€åˆ°å‘é‡æ£€ç´¢
            return self._create_vectorstore_retriever(vectorstore, **kwargs)
    
    def _create_vectorstore_retriever(self, vectorstore, **kwargs):
        """åˆ›å»ºå‘é‡æ£€ç´¢å™¨"""
        if not self.advanced_retrievers_available:
            return SimpleRetrieverService(vectorstore, kwargs.get('top_k', 10))
        
        try:
            # åªä¼ é€’VectorstoreRetrieverServiceéœ€è¦çš„å‚æ•°
            return self.VectorstoreRetrieverService.from_vectorstore(
                vectorstore=vectorstore,
                top_k=kwargs.get('top_k', 5),
                score_threshold=kwargs.get('score_threshold', 0.3)
            )
        except Exception as e:
            print(f"åˆ›å»ºVectorstoreRetrieverServiceå¤±è´¥: {e}")
            return SimpleRetrieverService(vectorstore, kwargs.get('top_k', 10))
    
    def _create_auto_retriever(self, vectorstore, **kwargs):
        """è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ£€ç´¢å™¨"""
        # æ£€æŸ¥æ–‡æ¡£æ•°é‡
        doc_count = self._estimate_document_count(vectorstore)
        
        # æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨å‘é‡å­˜å‚¨æ£€ç´¢å™¨
        force_vectorstore = kwargs.get('force_vectorstore', False)
        
        if force_vectorstore:
            print(f"å¼ºåˆ¶ä½¿ç”¨å‘é‡æ£€ç´¢({doc_count}ä¸ªæ–‡æ¡£)")
            return self._create_vectorstore_retriever(vectorstore, **kwargs)
        
        # ä¼˜å…ˆå°è¯•åˆ†å±‚æ£€ç´¢ï¼ˆä¸å—æ–‡æ¡£æ•°é‡é™åˆ¶ï¼‰
        print(f"æ£€æµ‹åˆ°çŸ¥è¯†åº“({doc_count}ä¸ªæ–‡æ¡£)ï¼Œä¼˜å…ˆå°è¯•åˆ†å±‚æ£€ç´¢")
        try:
            hierarchical_retriever = self._create_hierarchical_retriever(vectorstore, **kwargs)
            if hierarchical_retriever:
                print("âœ… ä½¿ç”¨åˆ†å±‚æ£€ç´¢")
                return hierarchical_retriever
            print("âš ï¸  åˆ†å±‚æ£€ç´¢ä¸å¯ç”¨ï¼Œå›é€€åˆ°å…³é”®è¯ç»„åˆæ£€ç´¢")
        except Exception as e:
            print(f"âš ï¸  åˆ†å±‚æ£€ç´¢åˆ›å»ºå¤±è´¥ï¼Œå›é€€åˆ°å…³é”®è¯ç»„åˆæ£€ç´¢: {e}")
        
        # å›é€€åˆ°å…³é”®è¯ç»„åˆæ£€ç´¢
        if doc_count > 50:
            print(f"ä½¿ç”¨å…³é”®è¯ç»„åˆæ£€ç´¢({doc_count}ä¸ªæ–‡æ¡£)")
            try:
                return self._create_keyword_ensemble_retriever(vectorstore, **kwargs)
            except Exception as e:
                print(f"å…³é”®è¯ç»„åˆæ£€ç´¢åˆ›å»ºå¤±è´¥ï¼Œå›é€€åˆ°å‘é‡æ£€ç´¢: {e}")
        
        # æœ€åå›é€€åˆ°ç®€å•å‘é‡æ£€ç´¢
        print(f"ä½¿ç”¨å‘é‡æ£€ç´¢({doc_count}ä¸ªæ–‡æ¡£)")
        return self._create_vectorstore_retriever(vectorstore, **kwargs)
    
    def _create_hierarchical_retriever(self, vectorstore, **kwargs):
        """åˆ›å»ºåˆ†å±‚æ£€ç´¢å™¨"""
        try:
            # å°è¯•å¤šç§å¯¼å…¥æ–¹å¼
            HierarchicalRetrieverService = None
            
            # æ–¹å¼1ï¼šå°è¯•ç»å¯¹å¯¼å…¥
            try:
                from dfy_langchain.retrievers.hierarchical_retriever import HierarchicalRetrieverService
            except ImportError:
                pass
            
            # æ–¹å¼2ï¼šå°è¯•ç›¸å¯¹å¯¼å…¥
            if HierarchicalRetrieverService is None:
                try:
                    from .retrievers.hierarchical_retriever import HierarchicalRetrieverService
                except ImportError:
                    pass
            
            # æ–¹å¼3ï¼šåŠ¨æ€å¯¼å…¥
            if HierarchicalRetrieverService is None:
                import importlib.util
                hierarchical_path = os.path.join(current_dir, "retrievers", "hierarchical_retriever.py")
                if os.path.exists(hierarchical_path):
                    spec = importlib.util.spec_from_file_location("hierarchical_retriever", hierarchical_path)
                    hierarchical_module = importlib.util.module_from_spec(spec)
                    spec.loader.exec_module(hierarchical_module)
                    HierarchicalRetrieverService = hierarchical_module.HierarchicalRetrieverService
            
            if HierarchicalRetrieverService is None:
                raise ImportError("æ— æ³•å¯¼å…¥ HierarchicalRetrieverService")
            
            # è·å–çŸ¥è¯†åº“IDå’Œå‘é‡å­˜å‚¨è·¯å¾„ä¿¡æ¯
            knowledge_base_id = kwargs.get('knowledge_base_id')
            vectorstore_path = None
            
            if knowledge_base_id:
                # å°è¯•ä»çŸ¥è¯†åº“ç®¡ç†å™¨è·å–å‘é‡å­˜å‚¨è·¯å¾„
                try:
                    # ç›´æ¥ä½¿ç”¨å½“å‰æ¨¡å—ä¸­çš„KnowledgeBaseManagerç±»
                    # é¿å…ç›¸å¯¹å¯¼å…¥é—®é¢˜
                    kb_manager = KnowledgeBaseManager(self)
                    kb_name = kb_manager.resolve_knowledge_base_name(knowledge_base_id)
                    if kb_name:
                        vectorstore_path = os.path.abspath(os.path.join("data", "knowledge_base", kb_name, "vector_store"))
                        print(f"ğŸ” è·å–åˆ°å‘é‡å­˜å‚¨è·¯å¾„: {vectorstore_path}")
                except Exception as e:
                    print(f"âš ï¸ è·å–å‘é‡å­˜å‚¨è·¯å¾„å¤±è´¥: {e}")
                    # å¦‚æœè·å–å¤±è´¥ï¼Œå°è¯•ç›´æ¥æ„é€ è·¯å¾„
                    try:
                        # åŠ è½½çŸ¥è¯†åº“é…ç½®
                        config_path = os.path.join("data", "knowledge_base", "knowledge_bases.json")
                        if os.path.exists(config_path):
                            import json
                            with open(config_path, 'r', encoding='utf-8') as f:
                                config = json.load(f)
                            kb_info = config.get(knowledge_base_id)
                            if kb_info:
                                kb_name = kb_info.get('name')
                                if kb_name:
                                    vectorstore_path = os.path.abspath(os.path.join("data", "knowledge_base", kb_name, "vector_store"))
                                    print(f"ğŸ” é€šè¿‡é…ç½®æ–‡ä»¶è·å–åˆ°å‘é‡å­˜å‚¨è·¯å¾„: {vectorstore_path}")
                    except Exception as e2:
                        print(f"âš ï¸ é€šè¿‡é…ç½®æ–‡ä»¶è·å–è·¯å¾„ä¹Ÿå¤±è´¥: {e2}")
            
            # æå–åˆ†å±‚æ£€ç´¢ç‰¹æœ‰çš„å‚æ•°ï¼Œé¿å…é‡å¤ä¼ é€’
            hierarchical_kwargs = {
                'vectorstore': vectorstore,
                'vectorstore_path': vectorstore_path,  # ä¼ é€’å‘é‡å­˜å‚¨è·¯å¾„
                'top_k': kwargs.get('top_k', 5),
                'score_threshold': kwargs.get('score_threshold', 0.3),
                'summary_top_k': kwargs.get('summary_top_k', 10),
                'summary_score_threshold': kwargs.get('summary_score_threshold', 0.4),
                'chunk_score_threshold': kwargs.get('chunk_score_threshold', 0.3),
                'enable_summary_fallback': kwargs.get('enable_summary_fallback', True)
            }
            
            # æ·»åŠ å…¶ä»–ä¸å†²çªçš„å‚æ•°
            for key, value in kwargs.items():
                if key not in hierarchical_kwargs:
                    hierarchical_kwargs[key] = value
            
            return HierarchicalRetrieverService.from_vectorstore(**hierarchical_kwargs)
        except ImportError as e:
            print(f"æ— æ³•å¯¼å…¥åˆ†å±‚æ£€ç´¢å™¨: {e}")
            return None
        except Exception as e:
            print(f"åˆ›å»ºåˆ†å±‚æ£€ç´¢å™¨å¤±è´¥: {e}")
            return None
    
    def _estimate_document_count(self, vectorstore):
        """ä¼°ç®—å‘é‡å­˜å‚¨ä¸­çš„æ–‡æ¡£æ•°é‡"""
        try:
            if hasattr(vectorstore, 'docstore') and hasattr(vectorstore.docstore, '_dict'):
                return len(vectorstore.docstore._dict)
            elif hasattr(vectorstore, 'index') and hasattr(vectorstore.index, 'ntotal'):
                return vectorstore.index.ntotal
            else:
                # é€šè¿‡æœç´¢ä¼°ç®—
                test_results = vectorstore.similarity_search("", k=1000)
                return len(test_results)
        except Exception:
            return 0


class ChinesePathHandler:
    """ä¸­æ–‡è·¯å¾„å¤„ç†å™¨ - è·¨å¹³å°æ”¯æŒ"""
    
    @staticmethod
    def get_short_path(path: str) -> Optional[str]:
        """è·å–WindowsçŸ­è·¯å¾„ï¼ˆä»…åœ¨Windowsä¸Šæœ‰æ•ˆï¼‰"""
        if os.name != 'nt':  # éWindowsç³»ç»Ÿ
            return None
            
        try:
            import ctypes
            from ctypes import wintypes
            
            GetShortPathNameW = ctypes.windll.kernel32.GetShortPathNameW
            GetShortPathNameW.argtypes = [wintypes.LPCWSTR, wintypes.LPWSTR, wintypes.DWORD]
            GetShortPathNameW.restype = wintypes.DWORD
            
            buffer_size = 1000
            buffer = ctypes.create_unicode_buffer(buffer_size)
            result = GetShortPathNameW(path, buffer, buffer_size)
            
            if result > 0:
                return buffer.value
            return None
        except Exception as e:
            print(f"è·å–çŸ­è·¯å¾„å¤±è´¥: {e}")
            return None
    
    @staticmethod
    def create_temp_copy(source_path: str) -> Optional[str]:
        """åˆ›å»ºä¸´æ—¶å‰¯æœ¬ - è·¨å¹³å°"""
        try:
            # ä½¿ç”¨è‹±æ–‡å‰ç¼€åˆ›å»ºä¸´æ—¶ç›®å½•ï¼Œç¡®ä¿è·¯å¾„ä¸åŒ…å«ä¸­æ–‡
            import uuid
            temp_dir = tempfile.mkdtemp(
                prefix=f"faiss_temp_{uuid.uuid4().hex[:8]}_", 
                dir=tempfile.gettempdir()
            )
            temp_path = os.path.join(temp_dir, "vector_store")
            
            # ç¡®ä¿æºè·¯å¾„å­˜åœ¨
            if not os.path.exists(source_path):
                print(f"æºè·¯å¾„ä¸å­˜åœ¨: {source_path}")
                return None
                
            # å¤åˆ¶æ•´ä¸ªç›®å½•
            shutil.copytree(source_path, temp_path)
            print(f"æˆåŠŸåˆ›å»ºä¸´æ—¶å‰¯æœ¬ï¼Œæº: {source_path}")
            print(f"ä¸´æ—¶è·¯å¾„: {temp_path}")
            return temp_path
        except Exception as e:
            print(f"åˆ›å»ºä¸´æ—¶å‰¯æœ¬å¤±è´¥: {e}")
            return None
    
    @staticmethod
    def cleanup_temp_path(temp_path: str):
        """æ¸…ç†ä¸´æ—¶è·¯å¾„ - è·¨å¹³å°"""
        if temp_path and os.path.exists(temp_path):
            try:
                # è·å–ä¸´æ—¶ç›®å½•çš„æ ¹ç›®å½•ï¼ˆé€šå¸¸æ˜¯temp_pathçš„çˆ¶ç›®å½•ï¼‰
                temp_root = os.path.dirname(temp_path)
                # æ£€æŸ¥æ˜¯å¦æ˜¯æˆ‘ä»¬åˆ›å»ºçš„ä¸´æ—¶ç›®å½•ï¼ˆåŒ…å«faiss_tempå‰ç¼€ï¼‰
                if os.path.basename(temp_root).startswith('faiss_temp_'):
                    shutil.rmtree(temp_root)
                    print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_root}")
                else:
                    # å¦‚æœä¸ç¡®å®šï¼Œåªæ¸…ç†vector_storeç›®å½•æœ¬èº«
                    shutil.rmtree(temp_path)
                    print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_path}")
            except Exception as e:
                print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
                # å°è¯•å¼ºåˆ¶åˆ é™¤
                try:
                    import time
                    time.sleep(0.1)  # çŸ­æš‚ç­‰å¾…ï¼Œé‡Šæ”¾æ–‡ä»¶å¥æŸ„
                    if os.path.exists(temp_path):
                        shutil.rmtree(temp_path, ignore_errors=True)
                except:
                    pass
    
    @staticmethod
    def has_chinese_chars(text: str) -> bool:
        """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
        return any('\u4e00' <= char <= '\u9fff' for char in text)
    
    @staticmethod
    def needs_path_processing(path: str) -> bool:
        """åˆ¤æ–­è·¯å¾„æ˜¯å¦éœ€è¦ç‰¹æ®Šå¤„ç†"""
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
        if ChinesePathHandler.has_chinese_chars(path):
            return True
        
        # åœ¨Windowsä¸Šï¼Œè¿˜å¯ä»¥æ£€æŸ¥å…¶ä»–å¯èƒ½æœ‰é—®é¢˜çš„å­—ç¬¦
        if os.name == 'nt':
            # Windowsä¸ŠæŸäº›ç‰¹æ®Šå­—ç¬¦å¯èƒ½å¯¼è‡´é—®é¢˜
            problematic_chars = ['ï¼Ÿ', 'ï¼Ÿ', 'ï¼š', 'ï½œ', 'ï¼Š', 'ï¼œ', 'ï¼', 'ï¼‚']
            return any(char in path for char in problematic_chars)
        
        return False
    
    @classmethod
    def process_chinese_path(cls, path: str) -> Tuple[str, Optional[str]]:
        """
        å¤„ç†ä¸­æ–‡è·¯å¾„ - è·¨å¹³å°
        è¿”å›: (å¤„ç†åçš„è·¯å¾„, ä¸´æ—¶è·¯å¾„æˆ–None)
        """
        if not cls.needs_path_processing(path):
            return path, None
        
        print(f"æ£€æµ‹åˆ°éœ€è¦å¤„ç†çš„è·¯å¾„ï¼Œå°è¯•å¤„ç†è·¯å¾„å…¼å®¹æ€§é—®é¢˜...")
        
        # Linux/Unixç³»ç»Ÿé€šå¸¸å¯¹UTF-8ç¼–ç çš„ä¸­æ–‡è·¯å¾„æ”¯æŒè‰¯å¥½
        if os.name != 'nt':
            # åœ¨Linuxä¸Šï¼Œé¦–å…ˆå°è¯•ç›´æ¥ä½¿ç”¨åŸè·¯å¾„
            try:
                # æµ‹è¯•è·¯å¾„æ˜¯å¦å¯ä»¥æ­£å¸¸è®¿é—®
                if os.path.exists(path) and os.access(path, os.R_OK):
                    print(f"Linuxç³»ç»Ÿç›´æ¥ä½¿ç”¨åŸè·¯å¾„: {path}")
                    return path, None
            except Exception as e:
                print(f"Linuxè·¯å¾„è®¿é—®æµ‹è¯•å¤±è´¥: {e}")
        
        # åˆ›å»ºä¸´æ—¶å‰¯æœ¬ï¼ˆWindowså’ŒLinuxéƒ½é€‚ç”¨ï¼‰
        temp_path = cls.create_temp_copy(path)
        if temp_path:
            print(f"åˆ›å»ºä¸´æ—¶å‰¯æœ¬: {temp_path}")
            return temp_path, temp_path
        
        # Windowsç‰¹æœ‰ï¼šå°è¯•çŸ­è·¯å¾„
        if os.name == 'nt':
            short_path = cls.get_short_path(path)
            if short_path and not cls.has_chinese_chars(short_path):
                print(f"ä½¿ç”¨WindowsçŸ­è·¯å¾„: {short_path}")
                return short_path, None
        
        print("æ— æ³•å¤„ç†è·¯å¾„ï¼Œä½¿ç”¨åŸè·¯å¾„")
        return path, None


class KnowledgeBaseManager:
    """çŸ¥è¯†åº“ç®¡ç†å™¨"""
    
    def __init__(self, factory: RetrieverServiceFactory):
        self.factory = factory
        self.path_handler = ChinesePathHandler()
        # æ·»åŠ æ£€ç´¢å™¨ç¼“å­˜ï¼Œé”®ä¸º(knowledge_base_ids_tuple, retriever_type, embedding_config_hash)
        self._retriever_cache = {}
        # ç¼“å­˜å¤§å°é™åˆ¶
        self._max_cache_size = 10
    
    def get_embedding_config_for_kb(self, knowledge_base_id: str) -> Optional[dict]:
        """è·å–çŸ¥è¯†åº“çš„embeddingé…ç½®"""
        try:
            # è·å–çŸ¥è¯†åº“é…ç½®
            kb_config = self.load_knowledge_bases_config()
            kb_info = kb_config.get(knowledge_base_id)
            
            if not kb_info:
                print(f"æœªæ‰¾åˆ°çŸ¥è¯†åº“ {knowledge_base_id} çš„é…ç½®")
                return None
            
            embedding_model_id = kb_info.get("embedding_model_id")
            if not embedding_model_id:
                print(f"çŸ¥è¯†åº“ {knowledge_base_id} æœªé…ç½®embeddingæ¨¡å‹")
                return None
            
            # åŠ¨æ€å¯¼å…¥æ•°æ®åº“ç›¸å…³æ¨¡å—ï¼ˆé¿å…å¾ªç¯å¯¼å…¥ï¼‰
            try:
                sys.path.append(os.path.join(os.path.dirname(current_dir), "app"))
                from database import get_db
                from app.services.model_config_service import ModelConfigService
                
                db = next(get_db())
                try:
                    model_config = ModelConfigService.get_model_config_by_id(db, embedding_model_id)
                    if not model_config:
                        print(f"æœªæ‰¾åˆ°IDä¸º {embedding_model_id} çš„embeddingæ¨¡å‹é…ç½®")
                        return None
                    
                    embedding_config = {
                        "id": model_config.id,
                        "provider": model_config.provider,
                        "model_name": model_config.model_name,
                        "api_key": model_config.api_key,
                        "endpoint": model_config.endpoint,
                        "model_type": model_config.model_type
                    }
                    
                    print(f"RAGæ£€ç´¢è·å–çŸ¥è¯†åº“ {knowledge_base_id} çš„embeddingé…ç½®: {model_config.model_name} ({model_config.provider})")
                    return embedding_config
                    
                finally:
                    db.close()
                    
            except ImportError as e:
                print(f"æ— æ³•å¯¼å…¥æ•°æ®åº“æ¨¡å—: {e}")
                return None
            except Exception as e:
                print(f"è·å–embeddingé…ç½®å¤±è´¥: {e}")
                return None
                
        except Exception as e:
            print(f"è·å–çŸ¥è¯†åº“embeddingé…ç½®å¤±è´¥: {e}")
            return None
    
    def load_knowledge_bases_config(self) -> Dict[str, Dict]:
        """åŠ è½½çŸ¥è¯†åº“é…ç½®"""
        try:
            # å°è¯•å¤šä¸ªå¯èƒ½çš„é…ç½®è·¯å¾„
            possible_paths = [
                os.path.join("data", "knowledge_base", "knowledge_bases.json"),
                os.path.join("..", "data", "knowledge_base", "knowledge_bases.json"),
                os.path.abspath(os.path.join("..", "data", "knowledge_base", "knowledge_bases.json"))
            ]
            
            kb_config_path = None
            for path in possible_paths:
                if os.path.exists(path):
                    kb_config_path = path
                    break
            
            if not kb_config_path:
                print(f"æœªæ‰¾åˆ°çŸ¥è¯†åº“é…ç½®æ–‡ä»¶ï¼Œå°è¯•çš„è·¯å¾„: {possible_paths}")
                return {}
            
            print(f"æ‰¾åˆ°é…ç½®æ–‡ä»¶: {kb_config_path}")
            with open(kb_config_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # è½¬æ¢ä¸ºä»¥IDä¸ºé”®çš„å­—å…¸
                result = {str(kb["id"]): kb for kb in data.get("knowledge_bases", [])}
                print(f"æˆåŠŸåŠ è½½é…ç½®ï¼ŒåŒ…å« {len(result)} ä¸ªçŸ¥è¯†åº“")
                return result
        except Exception as e:
            print(f"åŠ è½½çŸ¥è¯†åº“é…ç½®å¤±è´¥: {e}")
            return {}
    
    def resolve_knowledge_base_name(self, knowledge_base_id: str) -> Optional[str]:
        """è§£æçŸ¥è¯†åº“åç§°"""
        kb_config = self.load_knowledge_bases_config()
        
        # é€šè¿‡IDæŸ¥æ‰¾
        if knowledge_base_id in kb_config:
            kb_name = kb_config[knowledge_base_id]["name"]
            print(f"é€šè¿‡ID {knowledge_base_id} æ‰¾åˆ°çŸ¥è¯†åº“åç§°: {kb_name}")
            return kb_name
        
        # ç›´æ¥ä½¿ç”¨IDä½œä¸ºåç§°
        potential_path = os.path.join("data", "knowledge_base", knowledge_base_id)
        if os.path.exists(potential_path):
            print(f"ç›´æ¥ä½¿ç”¨ {knowledge_base_id} ä½œä¸ºçŸ¥è¯†åº“åç§°")
            return knowledge_base_id
        
        # é€šè¿‡åç§°åŒ¹é…
        for kb_id, kb_info in kb_config.items():
            if kb_info["name"] == knowledge_base_id:
                print(f"é€šè¿‡åç§°åŒ¹é…æ‰¾åˆ°çŸ¥è¯†åº“: {knowledge_base_id}")
                return knowledge_base_id
        
        print(f"æ— æ³•æ‰¾åˆ°çŸ¥è¯†åº“ {knowledge_base_id}ï¼Œè¯·æ£€æŸ¥çŸ¥è¯†åº“é…ç½®æˆ–åç§°")
        return None
    
    def load_faiss_vectorstore(self, knowledge_base_id: str):
        """åŠ è½½FAISSå‘é‡å­˜å‚¨"""
        if not self.factory.dependencies_available or not self.factory.embeddings:
            print("ä¾èµ–åº“æˆ–åµŒå…¥æ¨¡å‹ä¸å¯ç”¨")
            return None
        
        kb_name = self.resolve_knowledge_base_name(knowledge_base_id)
        if not kb_name:
            return None
        
        # å°è¯•å¤šä¸ªå¯èƒ½çš„å‘é‡å­˜å‚¨è·¯å¾„
        possible_paths = [
            os.path.join("data", "knowledge_base", kb_name, "vector_store"),
            os.path.join("..", "data", "knowledge_base", kb_name, "vector_store"),
            os.path.abspath(os.path.join("..", "data", "knowledge_base", kb_name, "vector_store"))
        ]
        
        vector_store_path = None
        for path in possible_paths:
            if os.path.exists(path):
                vector_store_path = os.path.abspath(path)
                print(f"æ‰¾åˆ°å‘é‡å­˜å‚¨è·¯å¾„: {vector_store_path}")
                break
        
        if not vector_store_path:
            print(f"çŸ¥è¯†åº“ {knowledge_base_id} çš„å‘é‡å­˜å‚¨è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•çš„è·¯å¾„: {possible_paths}")
            self._debug_missing_path(possible_paths[0])
            return None
        
        return self._load_vectorstore_with_path_handling(knowledge_base_id, vector_store_path, kb_name)
    
    def _debug_missing_path(self, vector_store_path: str):
        """è°ƒè¯•ç¼ºå¤±è·¯å¾„"""
        parent_dir = os.path.dirname(vector_store_path)
        if os.path.exists(parent_dir):
            print(f"çˆ¶ç›®å½•å†…å®¹: {os.listdir(parent_dir)}")
    
    def _load_vectorstore_with_path_handling(self, knowledge_base_id: str, vector_store_path: str, kb_name: str):
        """ä½¿ç”¨è·¯å¾„å¤„ç†åŠ è½½å‘é‡å­˜å‚¨"""
        print(f"æ­£åœ¨ä» {vector_store_path} åŠ è½½çŸ¥è¯†åº“ {knowledge_base_id} çš„å‘é‡å­˜å‚¨...")
        
        # æ£€æŸ¥å¿…éœ€çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        index_file = os.path.join(vector_store_path, "index.faiss")
        pkl_file = os.path.join(vector_store_path, "index.pkl")
        
        print(f"æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§:")
        print(f"  index.faiss: {os.path.exists(index_file)}")
        print(f"  index.pkl: {os.path.exists(pkl_file)}")
        
        if not os.path.exists(index_file) or not os.path.exists(pkl_file):
            print(f"ç¼ºå°‘å¿…éœ€çš„FAISSæ–‡ä»¶")
            if os.path.exists(vector_store_path):
                print(f"ç›®å½•å†…å®¹: {os.listdir(vector_store_path)}")
            return None
        
        processed_path, temp_path = self.path_handler.process_chinese_path(vector_store_path)
        
        try:
            print(f"å°è¯•ä»è·¯å¾„åŠ è½½: {processed_path}")
            vectorstore = self.factory.FAISS.load_local(
                folder_path=processed_path,
                embeddings=self.factory.embeddings,
                allow_dangerous_deserialization=True
            )
            print(f"æˆåŠŸåŠ è½½çŸ¥è¯†åº“ {knowledge_base_id} çš„å‘é‡å­˜å‚¨ï¼ŒåŒ…å« {len(vectorstore.docstore._dict)} ä¸ªæ–‡æ¡£")
            
            # å°è¯•å°†ç´¢å¼•è½¬ç§»åˆ° GPU
            vectorstore = self.factory._convert_index_to_gpu(vectorstore)
            vectorstore = self.factory._optimize_gpu_index(vectorstore)
            
            return vectorstore
            
        except Exception as e:
            print(f"åŠ è½½çŸ¥è¯†åº“ {knowledge_base_id} çš„å‘é‡å­˜å‚¨å¤±è´¥: {e}")
            return self._retry_load_with_encoding(knowledge_base_id, kb_name)
            
        finally:
            if temp_path:
                self.path_handler.cleanup_temp_path(temp_path)
    
    def _retry_load_with_encoding(self, knowledge_base_id: str, kb_name: str):
        """é‡è¯•åŠ è½½ï¼ˆç¼–ç å¤„ç†ï¼‰"""
        try:
            original_path = os.path.abspath(os.path.join("data", "knowledge_base", kb_name, "vector_store"))
            print(f"å°è¯•é‡æ–°ç¼–ç è·¯å¾„: {original_path}")
            
            vectorstore = self.factory.FAISS.load_local(
                folder_path=original_path,
                embeddings=self.factory.embeddings,
                allow_dangerous_deserialization=True
            )
            print(f"é‡æ–°ç¼–ç åæˆåŠŸåŠ è½½çŸ¥è¯†åº“ {knowledge_base_id} çš„å‘é‡å­˜å‚¨")
            
            # å°è¯•å°†ç´¢å¼•è½¬ç§»åˆ° GPU
            vectorstore = self.factory._convert_index_to_gpu(vectorstore)
            vectorstore = self.factory._optimize_gpu_index(vectorstore)
            
            return vectorstore
        except Exception as e2:
            print(f"é‡æ–°ç¼–ç ä¹Ÿå¤±è´¥: {e2}")
            return None
    
    def merge_vectorstores(self, vectorstores: List) -> Optional[Any]:
        """åˆå¹¶å¤šä¸ªå‘é‡å­˜å‚¨"""
        if not vectorstores:
            return None
        
        if len(vectorstores) == 1:
            return vectorstores[0]
        
        merged_vectorstore = vectorstores[0]
        for vs in vectorstores[1:]:
            if vs is not None:
                try:
                    merged_vectorstore.merge_from(vs)
                except Exception as e:
                    print(f"åˆå¹¶å‘é‡å­˜å‚¨æ—¶å‡ºé”™: {e}")
        
        return merged_vectorstore
    
    def create_retriever_service(self, knowledge_base_ids: List[str], **kwargs):
        """åˆ›å»ºæ£€ç´¢å™¨æœåŠ¡ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        if not knowledge_base_ids:
            print("æ²¡æœ‰æŒ‡å®šçŸ¥è¯†åº“ID")
            return None
        
        # è·å–æ£€ç´¢å™¨ç±»å‹
        retriever_type = kwargs.get('retriever_type', 'auto')
        
        # è·å–ç¬¬ä¸€ä¸ªçŸ¥è¯†åº“çš„embeddingé…ç½®ï¼ˆå‡è®¾æ‰€æœ‰çŸ¥è¯†åº“ä½¿ç”¨ç›¸åŒçš„embeddingé…ç½®ï¼‰
        embedding_config = None
        if knowledge_base_ids:
            embedding_config = self.get_embedding_config_for_kb(knowledge_base_ids[0])
        
        # ç”Ÿæˆç¼“å­˜é”®
        cache_key = self._generate_cache_key(knowledge_base_ids, retriever_type, embedding_config, kwargs)
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self._retriever_cache:
            print(f"âœ… ä»ç¼“å­˜è·å–æ£€ç´¢å™¨æœåŠ¡ (KB: {knowledge_base_ids}, Type: {retriever_type})")
            return self._retriever_cache[cache_key]
        
        print(f"ğŸ”„ åˆ›å»ºæ–°çš„æ£€ç´¢å™¨æœåŠ¡ (KB: {knowledge_base_ids}, Type: {retriever_type})")
        
        # å¦‚æœæœ‰embeddingé…ç½®ï¼Œåˆ›å»ºæ–°çš„factoryå®ä¾‹ä½¿ç”¨è¯¥é…ç½®
        if embedding_config:
            print(f"RAGæ£€ç´¢ä½¿ç”¨é…ç½®çš„embeddingæ¨¡å‹: {embedding_config['model_name']}")
            factory = RetrieverServiceFactory(embedding_config)
        else:
            print("RAGæ£€ç´¢ä½¿ç”¨é»˜è®¤çš„æœ¬åœ°embeddingæ¨¡å‹")
            factory = self.factory
        
        # åŠ è½½æ‰€æœ‰æŒ‡å®šçš„å‘é‡å­˜å‚¨ï¼ˆä½¿ç”¨é…ç½®çš„embeddingæ¨¡å‹ï¼‰
        vectorstores = []
        for kb_id in knowledge_base_ids:
            vs = self._load_faiss_vectorstore_with_factory(kb_id, factory)
            if vs is not None:
                vectorstores.append(vs)
        
        if not vectorstores:
            print("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•å‘é‡å­˜å‚¨")
            return None
        
        # åˆå¹¶å‘é‡å­˜å‚¨
        merged_vectorstore = self.merge_vectorstores(vectorstores)
        if merged_vectorstore is None:
            print("åˆå¹¶å‘é‡å­˜å‚¨å¤±è´¥")
            return None
        
        # ä¼ é€’çŸ¥è¯†åº“IDç»™æ£€ç´¢å™¨æœåŠ¡
        kwargs['knowledge_base_id'] = knowledge_base_ids[0] if knowledge_base_ids else None
        
        # åˆ›å»ºæ£€ç´¢å™¨æœåŠ¡
        retriever_service = factory.create_retriever_service(merged_vectorstore, **kwargs)
        
        if retriever_service:
            # ç¼“å­˜æ£€ç´¢å™¨æœåŠ¡
            self._cache_retriever_service(cache_key, retriever_service)
            print(f"âœ… æ£€ç´¢å™¨æœåŠ¡å·²ç¼“å­˜ (ç¼“å­˜å¤§å°: {len(self._retriever_cache)})")
        
        return retriever_service
    
    def _load_faiss_vectorstore_with_factory(self, knowledge_base_id: str, factory: RetrieverServiceFactory):
        """ä½¿ç”¨æŒ‡å®šçš„factoryåŠ è½½FAISSå‘é‡å­˜å‚¨"""
        if not factory.dependencies_available or not factory.embeddings:
            print("ä¾èµ–åº“æˆ–åµŒå…¥æ¨¡å‹ä¸å¯ç”¨")
            return None
        
        kb_name = self.resolve_knowledge_base_name(knowledge_base_id)
        if not kb_name:
            return None
        
        # å°è¯•å¤šä¸ªå¯èƒ½çš„å‘é‡å­˜å‚¨è·¯å¾„
        possible_paths = [
            os.path.join("data", "knowledge_base", kb_name, "vector_store"),
            os.path.join("..", "data", "knowledge_base", kb_name, "vector_store"),
            os.path.abspath(os.path.join("..", "data", "knowledge_base", kb_name, "vector_store"))
        ]
        
        vector_store_path = None
        for path in possible_paths:
            if os.path.exists(path):
                vector_store_path = os.path.abspath(path)
                print(f"æ‰¾åˆ°å‘é‡å­˜å‚¨è·¯å¾„: {vector_store_path}")
                break
        
        if not vector_store_path:
            print(f"çŸ¥è¯†åº“ {knowledge_base_id} çš„å‘é‡å­˜å‚¨è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•çš„è·¯å¾„: {possible_paths}")
            self._debug_missing_path(possible_paths[0])
            return None
        
        return self._load_vectorstore_with_path_handling_and_factory(knowledge_base_id, vector_store_path, kb_name, factory)
    
    def _load_vectorstore_with_path_handling_and_factory(self, knowledge_base_id: str, vector_store_path: str, kb_name: str, factory: RetrieverServiceFactory):
        """ä½¿ç”¨æŒ‡å®šçš„factoryå’Œè·¯å¾„å¤„ç†åŠ è½½å‘é‡å­˜å‚¨"""
        print(f"æ­£åœ¨ä» {vector_store_path} åŠ è½½çŸ¥è¯†åº“ {knowledge_base_id} çš„å‘é‡å­˜å‚¨...")
        
        # æ£€æŸ¥å¿…éœ€çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        index_file = os.path.join(vector_store_path, "index.faiss")
        pkl_file = os.path.join(vector_store_path, "index.pkl")
        
        print(f"æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§:")
        print(f"  index.faiss: {os.path.exists(index_file)}")
        print(f"  index.pkl: {os.path.exists(pkl_file)}")
        
        if not os.path.exists(index_file) or not os.path.exists(pkl_file):
            print(f"ç¼ºå°‘å¿…éœ€çš„FAISSæ–‡ä»¶")
            if os.path.exists(vector_store_path):
                print(f"ç›®å½•å†…å®¹: {os.listdir(vector_store_path)}")
            return None
        
        processed_path, temp_path = self.path_handler.process_chinese_path(vector_store_path)
        
        try:
            print(f"å°è¯•ä»è·¯å¾„åŠ è½½: {processed_path}")
            vectorstore = factory.FAISS.load_local(
                folder_path=processed_path,
                embeddings=factory.embeddings,
                allow_dangerous_deserialization=True
            )
            print(f"æˆåŠŸåŠ è½½çŸ¥è¯†åº“ {knowledge_base_id} çš„å‘é‡å­˜å‚¨ï¼ŒåŒ…å« {len(vectorstore.docstore._dict)} ä¸ªæ–‡æ¡£")
            
            # å°è¯•å°†ç´¢å¼•è½¬ç§»åˆ° GPU
            vectorstore = factory._convert_index_to_gpu(vectorstore)
            vectorstore = factory._optimize_gpu_index(vectorstore)
            
            return vectorstore
            
        except Exception as e:
            print(f"åŠ è½½çŸ¥è¯†åº“ {knowledge_base_id} çš„å‘é‡å­˜å‚¨å¤±è´¥: {e}")
            return self._retry_load_with_encoding_and_factory(knowledge_base_id, kb_name, factory)
            
        finally:
            if temp_path:
                self.path_handler.cleanup_temp_path(temp_path)
    
    def _retry_load_with_encoding_and_factory(self, knowledge_base_id: str, kb_name: str, factory: RetrieverServiceFactory):
        """é‡è¯•åŠ è½½ï¼ˆç¼–ç å¤„ç†ï¼‰ä½¿ç”¨æŒ‡å®šçš„factory"""
        try:
            original_path = os.path.abspath(os.path.join("data", "knowledge_base", kb_name, "vector_store"))
            print(f"å°è¯•é‡æ–°ç¼–ç è·¯å¾„: {original_path}")
            
            vectorstore = factory.FAISS.load_local(
                folder_path=original_path,
                embeddings=factory.embeddings,
                allow_dangerous_deserialization=True
            )
            print(f"é‡æ–°ç¼–ç åæˆåŠŸåŠ è½½çŸ¥è¯†åº“ {knowledge_base_id} çš„å‘é‡å­˜å‚¨")
            
            # å°è¯•å°†ç´¢å¼•è½¬ç§»åˆ° GPU
            vectorstore = factory._convert_index_to_gpu(vectorstore)
            vectorstore = factory._optimize_gpu_index(vectorstore)
            
            return vectorstore
        except Exception as e2:
            print(f"é‡æ–°ç¼–ç ä¹Ÿå¤±è´¥: {e2}")
            return None
    
    def _generate_cache_key(self, knowledge_base_ids: List[str], retriever_type: str, 
                           embedding_config: dict, kwargs: dict) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        import hashlib
        import json
        
        # åˆ›å»ºç¼“å­˜é”®çš„ç»„æˆéƒ¨åˆ†
        kb_ids_tuple = tuple(sorted(knowledge_base_ids))
        
        # å¤„ç†embeddingé…ç½®
        embedding_hash = "none"
        if embedding_config:
            # åªä½¿ç”¨å…³é”®é…ç½®é¡¹ç”Ÿæˆhashï¼Œé¿å…åŒ…å«æ•æ„Ÿä¿¡æ¯
            config_for_hash = {
                "provider": embedding_config.get("provider"),
                "model_name": embedding_config.get("model_name"),
                "model_type": embedding_config.get("model_type")
            }
            embedding_hash = hashlib.md5(json.dumps(config_for_hash, sort_keys=True).encode()).hexdigest()[:8]
        
        # å¤„ç†å…¶ä»–å…³é”®å‚æ•°
        cache_relevant_kwargs = {
            "top_k": kwargs.get("top_k", 5),
            "score_threshold": kwargs.get("score_threshold", 0.3),
            "summary_top_k": kwargs.get("summary_top_k", 10),
            "summary_score_threshold": kwargs.get("summary_score_threshold", 0.4),
            "chunk_score_threshold": kwargs.get("chunk_score_threshold", 0.3)
        }
        kwargs_hash = hashlib.md5(json.dumps(cache_relevant_kwargs, sort_keys=True).encode()).hexdigest()[:8]
        
        # ç”Ÿæˆæœ€ç»ˆçš„ç¼“å­˜é”®
        cache_key = f"{kb_ids_tuple}_{retriever_type}_{embedding_hash}_{kwargs_hash}"
        return cache_key
    
    def _cache_retriever_service(self, cache_key: str, retriever_service):
        """ç¼“å­˜æ£€ç´¢å™¨æœåŠ¡"""
        # å¦‚æœç¼“å­˜å·²æ»¡ï¼Œç§»é™¤æœ€æ—§çš„æ¡ç›®ï¼ˆç®€å•çš„LRUç­–ç•¥ï¼‰
        if len(self._retriever_cache) >= self._max_cache_size:
            # ç§»é™¤ç¬¬ä¸€ä¸ªï¼ˆæœ€æ—§çš„ï¼‰æ¡ç›®
            oldest_key = next(iter(self._retriever_cache))
            del self._retriever_cache[oldest_key]
            print(f"ğŸ—‘ï¸  ç¼“å­˜å·²æ»¡ï¼Œç§»é™¤æœ€æ—§çš„æ£€ç´¢å™¨: {oldest_key}")
        
        # æ·»åŠ åˆ°ç¼“å­˜
        self._retriever_cache[cache_key] = retriever_service
    
    def clear_retriever_cache(self):
        """æ¸…ç©ºæ£€ç´¢å™¨ç¼“å­˜"""
        self._retriever_cache.clear()
        print("ğŸ—‘ï¸  æ£€ç´¢å™¨ç¼“å­˜å·²æ¸…ç©º")
    
    def get_cache_info(self) -> dict:
        """è·å–ç¼“å­˜ä¿¡æ¯"""
        return {
            "cache_size": len(self._retriever_cache),
            "max_cache_size": self._max_cache_size,
            "cached_keys": list(self._retriever_cache.keys())
        }


class DocumentSearcher:
    """æ–‡æ¡£æœç´¢å™¨"""
    
    def __init__(self):
        # åˆ›å»ºé»˜è®¤çš„factoryï¼Œä½†ä¼šåœ¨search_documentsä¸­æ ¹æ®çŸ¥è¯†åº“åŠ¨æ€åˆ›å»ºæ–°çš„manager
        self.default_factory = RetrieverServiceFactory()
    
    def search_documents(self, query: str, knowledge_base_ids: List[str] = None, 
                        top_k: int = 5, return_scores: bool = False,
                        enable_context_enrichment: bool = True, 
                        enable_ranking: bool = True,
                        keyword_threshold: int = 1,
                        context_window: int = 150,
                        score_threshold: float = 0.3,
                        weight_keyword_freq: float = 0.4,
                        weight_keyword_pos: float = 0.3,
                        weight_keyword_coverage: float = 0.3,
                        retriever_type: str = "auto",
                        force_vectorstore: bool = False) -> List:
        """
        æœç´¢ç›¸å…³æ–‡æ¡£
        
        å‚æ•°:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
            knowledge_base_ids: çŸ¥è¯†åº“IDåˆ—è¡¨
            top_k: è¿”å›çš„æ–‡æ¡£æ•°é‡
            return_scores: æ˜¯å¦è¿”å›ç›¸å…³æ€§åˆ†æ•°
            enable_context_enrichment: æ˜¯å¦å¯ç”¨ä¸Šä¸‹æ–‡å¢å¼ºåŠŸèƒ½
            enable_ranking: æ˜¯å¦å¯ç”¨ç›¸å…³æ€§æ’åºåŠŸèƒ½
            keyword_threshold: å…³é”®è¯åŒ¹é…é˜ˆå€¼ï¼ˆè‡³å°‘åŒ…å«å¤šå°‘ä¸ªå…³é”®è¯æ‰ç®—åŒ¹é…ï¼‰
            context_window: ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
            score_threshold: ç›¸ä¼¼åº¦åˆ†æ•°é˜ˆå€¼
            weight_keyword_freq: å…³é”®è¯é¢‘ç‡æƒé‡
            weight_keyword_pos: å…³é”®è¯ä½ç½®æƒé‡
            weight_keyword_coverage: å…³é”®è¯è¦†ç›–åº¦æƒé‡
            retriever_type: æ£€ç´¢å™¨ç±»å‹ ("auto", "keyword_ensemble", "vectorstore")
            
        è¿”å›:
            å¦‚æœreturn_scoresä¸ºTrueï¼Œè¿”å›(æ–‡æ¡£, åˆ†æ•°)çš„å…ƒç»„åˆ—è¡¨
            å¦åˆ™ï¼Œè¿”å›æ–‡æ¡£åˆ—è¡¨
        """
        if not knowledge_base_ids:
            print("æ²¡æœ‰æŒ‡å®šçŸ¥è¯†åº“IDï¼Œæ— æ³•è¿›è¡Œæ£€ç´¢")
            return []
        

        
        # ä¸ºæ¯æ¬¡æœç´¢åˆ›å»ºæ–°çš„KnowledgeBaseManagerï¼Œç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„embeddingé…ç½®
        kb_manager = KnowledgeBaseManager(self.default_factory)
        
        # å°†RAGé…ç½®å‚æ•°ä¼ é€’ç»™æ£€ç´¢å™¨æœåŠ¡
        retriever_kwargs = {
            'top_k': top_k,
            'score_threshold': score_threshold,
            'keyword_match_threshold': keyword_threshold,
            'context_window': context_window if enable_context_enrichment else 0,
            'enable_ranking': enable_ranking,
            'weight_keyword_freq': weight_keyword_freq,
            'weight_keyword_pos': weight_keyword_pos,
            'weight_keyword_coverage': weight_keyword_coverage,
            'retriever_type': retriever_type,
            'force_vectorstore': force_vectorstore,
            'knowledge_base_id': knowledge_base_ids[0] if knowledge_base_ids else None  # ä¼ é€’ç»™åˆ†å±‚æ£€ç´¢å™¨
        }
        
        retriever_service = kb_manager.create_retriever_service(knowledge_base_ids, **retriever_kwargs)
        if not retriever_service:
            print("æ— æ³•åˆ›å»ºæ£€ç´¢å™¨æœåŠ¡")
            return []
        
        return self._execute_search(retriever_service, query, top_k, return_scores,
                                  enable_context_enrichment, enable_ranking, knowledge_base_ids)
    
    def _execute_search(self, retriever_service, query: str, top_k: int, 
                       return_scores: bool, enable_context_enrichment: bool, 
                       enable_ranking: bool, knowledge_base_ids: List[str] = None) -> List:
        """æ‰§è¡Œæœç´¢"""
        # ä¿å­˜åŸå§‹è®¾ç½®
        original_context = getattr(retriever_service, 'context_window', 0) > 0
        original_ranking = getattr(retriever_service, 'enable_ranking', True)
        
        results = []
        
        try:
            # åº”ç”¨ä¸´æ—¶è®¾ç½®
            self._apply_search_settings(retriever_service, enable_context_enrichment, 
                                      enable_ranking, original_context, original_ranking)
            
            # æ‰§è¡Œæ£€ç´¢
            if return_scores:
                results = retriever_service.get_relevant_documents_with_scores(query)
            else:
                results = retriever_service.get_relevant_documents(query)
            
            results = results[:top_k]
            
        except Exception as e:
            print(f"æ£€ç´¢è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            results = []
            
        finally:
            # æ¢å¤åŸå§‹è®¾ç½®
            self._restore_search_settings(retriever_service, original_context, original_ranking)
        
        # å¦‚æœå‘é‡æ£€ç´¢å¤±è´¥æˆ–è¿”å›ç©ºç»“æœï¼Œå°è¯•Excelå›é€€æ£€ç´¢
        if not results:
            print("âš ï¸ å‘é‡æ£€ç´¢æœªæ‰¾åˆ°ç»“æœï¼Œå°è¯•Excelå›é€€æ£€ç´¢...")
            try:
                from excel_fallback_retriever import excel_fallback_search
                excel_docs = excel_fallback_search(query, knowledge_base_ids, top_k)
                if excel_docs:
                    print(f"âœ… Excelå›é€€æ£€ç´¢æ‰¾åˆ° {len(excel_docs)} ä¸ªç»“æœ")
                    results = excel_docs
                else:
                    print("âŒ Excelå›é€€æ£€ç´¢ä¹Ÿæœªæ‰¾åˆ°ç»“æœ")
            except Exception as e:
                print(f"Excelå›é€€æ£€ç´¢å¤±è´¥: {e}")
        
        return results
    
    def _apply_search_settings(self, retriever_service, enable_context_enrichment: bool,
                              enable_ranking: bool, original_context: bool, original_ranking: bool):
        """åº”ç”¨æœç´¢è®¾ç½®"""
        if (hasattr(retriever_service, 'context_window') and 
            enable_context_enrichment != original_context):
            retriever_service.context_window = 150 if enable_context_enrichment else 0
            
        if (hasattr(retriever_service, 'enable_ranking') and 
            enable_ranking != original_ranking):
            retriever_service.enable_ranking = enable_ranking
    
    def _restore_search_settings(self, retriever_service, original_context: bool, 
                                original_ranking: bool):
        """æ¢å¤æœç´¢è®¾ç½®"""
        if hasattr(retriever_service, 'context_window'):
            retriever_service.context_window = 150 if original_context else 0
            
        if hasattr(retriever_service, 'enable_ranking'):
            retriever_service.enable_ranking = original_ranking


class DocumentInfoExtractor:
    """æ–‡æ¡£ä¿¡æ¯æå–å™¨"""
    
    @staticmethod
    def get_document_source_info(doc) -> str:
        """è·å–æ–‡æ¡£çš„è¯¦ç»†æ¥æºä¿¡æ¯"""
        source = doc.metadata.get("source", "æœªçŸ¥æ¥æº")
        filename = os.path.basename(source) if source else "æœªçŸ¥æ–‡æ¡£"
        
        source_info = [f"æ–‡ä»¶å: {filename}"]
        
        # æ·»åŠ å„ç§å…ƒæ•°æ®
        metadata_mappings = {
            "page": "é¡µç ",
            "row": "è¡Œå·", 
            "created_at": "åˆ›å»ºæ—¶é—´",
            "author": "ä½œè€…"
        }
        
        for key, label in metadata_mappings.items():
            if key in doc.metadata:
                source_info.append(f"{label}: {doc.metadata[key]}")
        
        return "\n".join(source_info)
    
    @staticmethod
    def get_document_type(source: str) -> str:
        """è·å–æ–‡æ¡£ç±»å‹"""
        if not source:
            return "æœªçŸ¥ç±»å‹"
        
        type_mappings = {
            (".pdf", ".PDF"): "PDFæ–‡æ¡£",
            (".docx", ".DOCX"): "Wordæ–‡æ¡£", 
            (".xlsx", ".XLSX"): "Excelæ–‡æ¡£"
        }
        
        for extensions, doc_type in type_mappings.items():
            if source.endswith(extensions):
                return doc_type
        
        return "å…¶ä»–æ–‡æ¡£"


# å…¨å±€å®ä¾‹
_document_searcher = DocumentSearcher()
_info_extractor = DocumentInfoExtractor()

# å…¼å®¹æ€§æ¥å£
def search_documents(query: str, knowledge_base_ids: List[str] = None, top_k: int = 5,
                    return_scores: bool = False, enable_context_enrichment: bool = True,
                    enable_ranking: bool = True,
                    keyword_threshold: int = 1,
                    context_window: int = 150,
                    score_threshold: float = 0.3,
                    weight_keyword_freq: float = 0.4,
                    weight_keyword_pos: float = 0.3,
                    weight_keyword_coverage: float = 0.3,
                    force_vectorstore: bool = False,
                    retriever_type: str = "auto") -> List:
    """æœç´¢æ–‡æ¡£çš„å…¼å®¹æ€§æ¥å£"""
    return _document_searcher.search_documents(
        query, knowledge_base_ids, top_k, return_scores, 
        enable_context_enrichment, enable_ranking,
        keyword_threshold, context_window, score_threshold,
        weight_keyword_freq, weight_keyword_pos, weight_keyword_coverage,
        retriever_type=retriever_type,
        force_vectorstore=force_vectorstore
    )

def get_document_source_info(doc) -> str:
    """è·å–æ–‡æ¡£æ¥æºä¿¡æ¯çš„å…¼å®¹æ€§æ¥å£"""
    return _info_extractor.get_document_source_info(doc)


def main():
    """æµ‹è¯•ä¸»å‡½æ•°"""
    test_queries = ["é’Ÿæ›¦ç‘¶æŠ•è¯‰çš„å†…å®¹"]
    test_kb_ids = ["1", "æµ‹è¯•ç”¨"]
    show_scores = True
    enable_context = True
    enable_ranking = True
    
    for test_query in test_queries:
        print(f"\næŸ¥è¯¢: '{test_query}'")
        print(f"ä½¿ç”¨çŸ¥è¯†åº“: {test_kb_ids}")
        print(f"ä¸Šä¸‹æ–‡å¢å¼º: {'å·²å¯ç”¨' if enable_context else 'å·²ç¦ç”¨'}")
        print(f"ç›¸å…³æ€§æ’åº: {'å·²å¯ç”¨' if enable_ranking else 'å·²ç¦ç”¨'}")
        
        results = search_documents(
            test_query, 
            knowledge_base_ids=test_kb_ids,
            return_scores=show_scores,
            enable_context_enrichment=enable_context,
            enable_ranking=enable_ranking
        )
        
        print(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£:")
        
        for i, item in enumerate(results, 1):
            if show_scores:
                doc, scores = item
                print(f"\næ–‡æ¡£ {i} ({os.path.basename(doc.metadata.get('source', 'æœªçŸ¥'))}):")
                print(f"ä¸Šä¸‹æ–‡å¢å¼º: {'æ˜¯' if doc.metadata.get('context_enriched', False) else 'å¦'}")
                print(f"æ¥æºä¿¡æ¯:\n{get_document_source_info(doc)}")
                print(f"æ–‡æ¡£ç±»å‹: {_info_extractor.get_document_type(doc.metadata.get('source', ''))}")
                print(f"ç›¸å…³æ€§åˆ†æ•°:")
                for score_name, score_value in scores.items():
                    print(f"  - {score_name}: {score_value:.4f}")
                print(f"å†…å®¹:\n{doc.page_content}")
            else:
                doc = item
                print(f"\næ–‡æ¡£ {i} ({os.path.basename(doc.metadata.get('source', 'æœªçŸ¥'))}):")
                print(f"æ¥æºä¿¡æ¯:\n{get_document_source_info(doc)}")
                print(f"å†…å®¹:\n{doc.page_content}")
            print("-" * 50)


if __name__ == "__main__":
    main()